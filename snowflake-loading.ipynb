{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "420632e7-c0d1-4134-a309-279d92b3596a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snowflake options are set.\n"
     ]
    }
   ],
   "source": [
    "# Setting up Snowflake Connection \n",
    "\n",
    "sf_user = \"SHIV*****\"\n",
    "sf_password = \"************\"\n",
    "sf_url = \"*******-*******.snowflakecomputing.com\" \n",
    "sf_warehouse = \"COMPUTE_WH\" \n",
    "sf_database = \"RETAIL_DB\"  \n",
    "sf_schema = \"ANALYTICS\"   \n",
    "\n",
    "#Creating the Snowflake options dictionary \n",
    "snowflake_options = {\n",
    "  \"sfUrl\": sf_url,\n",
    "  \"sfUser\": sf_user,\n",
    "  \"sfPassword\": sf_password,\n",
    "  \"sfDatabase\": sf_database,\n",
    "  \"sfSchema\": sf_schema,\n",
    "  \"sfWarehouse\": sf_warehouse\n",
    "}\n",
    "\n",
    "print(\"Snowflake options are set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0c1cb2b-ae21-4c56-9e18-b7b33300fbea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Service Principal configured for ADLS access.\n"
     ]
    }
   ],
   "source": [
    "# Configuring Service Principal\n",
    "STORAGE_ACCOUNT_NAME = \"adlsshivendra\"\n",
    "ADLS_CONTAINER_NAME = \"raw\"\n",
    "CLIENT_ID = \"4069d864-2ea2-4354-a634-71a8488be89e\"\n",
    "TENANT_ID = \"4ac50105-0c66-404e-a107-7cbd8a9a6442\"\n",
    "CLIENT_SECRET = \"o.O8Q~ARpL1hfZzcjC_yJZTPhhc-jTCDlI_BRdif\"\n",
    "\n",
    "#Spark Configuration\n",
    "spark.conf.set(f\"fs.azure.account.auth.type.{STORAGE_ACCOUNT_NAME}.dfs.core.windows.net\", \"OAuth\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth.provider.type.{STORAGE_ACCOUNT_NAME}.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.id.{STORAGE_ACCOUNT_NAME}.dfs.core.windows.net\", CLIENT_ID)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.secret.{STORAGE_ACCOUNT_NAME}.dfs.core.windows.net\", CLIENT_SECRET)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.endpoint.{STORAGE_ACCOUNT_NAME}.dfs.core.windows.net\", f\"https://login.microsoftonline.com/{TENANT_ID}/oauth2/token\")\n",
    "\n",
    "print(\"Service Principal configured for ADLS access.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4309a7a6-b9db-4f63-b0e4-0ac8820ac842",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Loading Silver Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e77d203f-6569-45ca-8864-2d52a8d2bc13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded FACT_ORDERS.\n"
     ]
    }
   ],
   "source": [
    "#Loading 'silver_fact_orders' to Snowflake\n",
    "\n",
    "table_to_load = \"silver_fact_orders\"\n",
    "snowflake_table_name = \"FACT_ORDERS\" \n",
    "\n",
    "# 1. Reading the Delta table from Databricks\n",
    "df = spark.table(table_to_load)\n",
    "\n",
    "# 2. Writing the DataFrame to Snowflake\n",
    "df.write \\\n",
    "  .format(\"snowflake\") \\\n",
    "  .options(**snowflake_options) \\\n",
    "  .option(\"dbtable\", snowflake_table_name) \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .save()\n",
    "  \n",
    "print(f\"Successfully loaded {snowflake_table_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "864e4bd9-6a28-491d-a74f-18dbc18d2978",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Loading 'silver_fact_orders' to Snowflake\n",
    "\n",
    "table_to_load = \"silver_fact_orders\"\n",
    "snowflake_table_name = \"FACT_ORDERS\" \n",
    "\n",
    "# 1. Reading the Delta table from Databricks\n",
    "df = spark.table(table_to_load)\n",
    "\n",
    "# 2. Writing the DataFrame to Snowflake\n",
    "df.write \\\n",
    "  .format(\"snowflake\") \\\n",
    "  .options(**snowflake_options) \\\n",
    "  .option(\"dbtable\", snowflake_table_name) \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .save()\n",
    "  \n",
    "print(f\"Successfully loaded {snowflake_table_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc21db5d-fd52-43e0-90c3-68db3149c0d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded DIM_CUSTOMERS.\n"
     ]
    }
   ],
   "source": [
    "#Loading 'silver_customers' to Snowflake\n",
    "\n",
    "table_to_load = \"silver_customers\"\n",
    "snowflake_table_name = \"DIM_CUSTOMERS\" \n",
    "\n",
    "# 1. Reading the Delta table from Databricks\n",
    "df = spark.table(table_to_load)\n",
    "\n",
    "# 2. Writing the DataFrame to Snowflake\n",
    "df.write \\\n",
    "  .format(\"snowflake\") \\\n",
    "  .options(**snowflake_options) \\\n",
    "  .option(\"dbtable\", snowflake_table_name) \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .save()\n",
    "  \n",
    "print(f\"Successfully loaded {snowflake_table_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "280d8d5b-dfe8-41e5-9a58-e3c196834b11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded DIM_PRODUCTS.\n"
     ]
    }
   ],
   "source": [
    "#Loading 'silver_products' to Snowflake\n",
    "\n",
    "table_to_load = \"silver_products\"\n",
    "snowflake_table_name = \"DIM_PRODUCTS\" \n",
    "\n",
    "# 1. Reading the Delta table from Databricks\n",
    "df = spark.table(table_to_load)\n",
    "\n",
    "# 2. Writing the DataFrame to Snowflake\n",
    "df.write \\\n",
    "  .format(\"snowflake\") \\\n",
    "  .options(**snowflake_options) \\\n",
    "  .option(\"dbtable\", snowflake_table_name) \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .save()\n",
    "  \n",
    "print(f\"Successfully loaded {snowflake_table_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "587fb725-6ac5-41c1-b2b1-5bc04e749e6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded DIM_STORES.\n"
     ]
    }
   ],
   "source": [
    "#Loading 'silver_stores' to Snowflake\n",
    "\n",
    "table_to_load = \"silver_stores\"\n",
    "snowflake_table_name = \"DIM_STORES\" \n",
    "\n",
    "# 1. Reading the Delta table from Databricks\n",
    "df = spark.table(table_to_load)\n",
    "\n",
    "# 2. Writing the DataFrame to Snowflake\n",
    "df.write \\\n",
    "  .format(\"snowflake\") \\\n",
    "  .options(**snowflake_options) \\\n",
    "  .option(\"dbtable\", snowflake_table_name) \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .save()\n",
    "  \n",
    "print(f\"Successfully loaded {snowflake_table_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e17e5468-73c8-4331-bafd-88e2c7ce9a2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded DIM_PAYMENTS.\n"
     ]
    }
   ],
   "source": [
    "#Loading 'silver_payments' to Snowflake\n",
    "\n",
    "table_to_load = \"silver_payments\"\n",
    "snowflake_table_name = \"DIM_PAYMENTS\" \n",
    "\n",
    "# 1. Reading the Delta table from Databricks\n",
    "df = spark.table(table_to_load)\n",
    "\n",
    "# 2. Writing the DataFrame to Snowflake\n",
    "df.write \\\n",
    "  .format(\"snowflake\") \\\n",
    "  .options(**snowflake_options) \\\n",
    "  .option(\"dbtable\", snowflake_table_name) \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .save()\n",
    "  \n",
    "print(f\"Successfully loaded {snowflake_table_name}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1c3633d0-c7d2-488b-9cef-29cad3337023",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Loading Gold Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "864ef8a5-9897-412c-bfbb-36550d50398e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded GOLD_CURRENT_INVENTORY.\n",
      "Successfully loaded GOLD_CUSTOMER_TIER_ANALYSIS.\n",
      "Successfully loaded GOLD_DAILY_FRAUD_SUMMARY.\n",
      "Successfully loaded GOLD_DAILY_SALES_SUMMARY.\n",
      "Successfully loaded GOLD_FRAUD_ALERTS.\n",
      "Successfully loaded GOLD_MONTHLY_PRODUCT_SALES.\n",
      "Successfully loaded GOLD_SALES_BY_CHANNEL_PAYMENT.\n"
     ]
    }
   ],
   "source": [
    "# List of Gold tables to load\n",
    "tables_to_load = [\n",
    "    \"gold_current_inventory\",\n",
    "    \"gold_customer_tier_analysis\",\n",
    "    \"gold_daily_fraud_summary\",\n",
    "    \"gold_daily_sales_summary\",\n",
    "    \"gold_fraud_alerts\",\n",
    "    \"gold_monthly_product_sales\",\n",
    "    \"gold_sales_by_channel_payment\"\n",
    "]\n",
    "\n",
    "# Loading using loop\n",
    "for table in tables_to_load:\n",
    "    snowflake_table_name = table.upper()  # convert to uppercase for Snowflake\n",
    "    \n",
    "    \n",
    "    # Reading the Delta table\n",
    "    df = spark.table(table)\n",
    "    \n",
    "    # Writing to Snowflake\n",
    "    df.write \\\n",
    "      .format(\"snowflake\") \\\n",
    "      .options(**snowflake_options) \\\n",
    "      .option(\"dbtable\", snowflake_table_name) \\\n",
    "      .mode(\"overwrite\") \\\n",
    "      .save()\n",
    "    \n",
    "    print(f\"Successfully loaded {snowflake_table_name}.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "snowflake-loading",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
